# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

base:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/01_raw/base.csv
  credentials: gcp_credentials
  load_args:
    sep: ","

xs:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/01_raw/xs.csv
  credentials: gcp_credentials
  load_args:
    sep: ","

pre_processed_df:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/02_intermediate/pre_processed_df.csv
  credentials: gcp_credentials
  load_args:
    sep: ","

features_df:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/03_feature/features_df.csv
  credentials: gcp_credentials
  load_args:
    sep: ","

X:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/X.csv
  credentials: gcp_credentials

y_churn:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_churn.csv
  credentials: gcp_credentials

X_train:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/X_train.csv
  credentials: gcp_credentials

X_test:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/X_test.csv
  credentials: gcp_credentials

y_train_churn:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_train_churn.csv
  credentials: gcp_credentials

y_test_churn:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_test_churn.csv
  credentials: gcp_credentials

CT:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/06_models/CT.pkl
  credentials: gcp_credentials
  backend: pickle

y_ltv:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_ltv.csv
  credentials: gcp_credentials


y_train_ltv:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_train_ltv.csv
  credentials: gcp_credentials

y_test_ltv:
  type: pandas.CSVDataSet
  filepath: gs://ltv_analysis_data/data/04_model_input/y_test_ltv.csv
  credentials: gcp_credentials


survival_model:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/06_models/survival_model.pkl
  credentials: gcp_credentials
  backend: pickle

trained_classifier_pipeline:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/06_models/trained_classifier_pipeline.pkl
  credentials: gcp_credentials
  backend: pickle

trained_ltv_pipeline:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/06_models/trained_ltv_pipeline.pkl
  credentials: gcp_credentials
  backend: pickle

trained_kfolds:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/06_models/trained_kfolds.pkl
  credentials: gcp_credentials
  backend: pickle


classification_metrics: 
  type: matplotlib.MatplotlibWriter
  filepath: gs://ltv_analysis_data/data/08_reporting/classification_metrics.png
  credentials: gcp_credentials
  save_args:
    format: png

elbow_curve: 
  type: matplotlib.MatplotlibWriter
  filepath: gs://ltv_analysis_data/data/08_reporting/elbow_curve.png
  credentials: gcp_credentials
  save_args:
    format: png

cluster_centroids:
  type: pickle.PickleDataSet
  filepath: gs://ltv_analysis_data/data/08_reporting/cluster_centroids.pkl
  credentials: gcp_credentials
  backend: pickle